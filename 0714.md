
A. Last week you did an exercise where you manually applied a 3x3 array as a filter to an image of two people ascending an outdoor staircase. Modify the existing filter and if needed the associated weight in order to apply your new filters to the image 3 times. Plot each result, upload them to your response, and describe how each filter transformed the existing image as it convolved through the original array and reduced the object size. What are you functionally accomplishing as you apply the filter to your original array (see the following snippet for reference)? Why is the application of a convolving filter to an image useful for computer vision?

![image005](https://github.com/dshuangg/responses/raw/master/image005.png)

This filter was able to eliminate the shades of grey and simply extract and make the edges more prominent, though thin. It seems like it's able to distinctly highlight corners and edges, but is most useful to be used to define edges since it turns all the "colors" into black and has the only white part being the lines and edges of each object in the image!

![image006](https://github.com/dshuangg/responses/raw/master/image006.png)

This filter was able to highlight the vertical lines in the image. It has less of a focus towards horizontal lines and highlights the vertical lines. Though, it's important to note that slanted lines are still highlighted, just more so the more the lines become vertical.

![image007](https://github.com/dshuangg/responses/raw/master/image007.png)

Similar to the previous one (but the exact opposite), this filter was able to highlight the horizontal lines, instead, in the image. It has less of a focus towards vertical lines and highlights the horizontal lines. It's important to note that slanted lines are still highlighted, just more so the more the lines become horizontal.

When applying these filters to the original array, it functionally converts the images into usable images that highlights things that the machine will be better able to interpret, into basic lines and such. The filter grabs the cells and pixels around each pixel (that aren't along the edges) and multiplies it according to the importance defined in the filter (which becomes the convolution of each). This is useful for computer vision because then the computers can much more easily break down each image into basic qualities, since computer vision has to be taught to see at a basic, fundamental level before it can see at a more complex level. It's useful for machines to begin identifying things within images!

B. Another useful method is pooling. Apply a 2x2 filter to one of your convolved images, and plot the result. In effect what have you accomplished by applying this filter? Can you determine from the code which type of pooling filter is applied, and the method for selecting a pixel value (see the following snippet)? Did the result increase in size or decrease? Why would this method be method? Stretch goal: again, instead of using misc.ascent(), apply the pooling filter to one of your transformed images. 

![image008](https://github.com/dshuangg/responses/raw/master/image008.png)

By applying this filter, the image is actually half the x length and half the y length, effectively making it a quarter of its original image size (or rather, half in length... however you wish to call it)! As a result, the image looks like it's a lot more low-resolution. (But in my output, I've set the image to be just as large--8 by 8--for ease of visibility.) By doing so, the machine has taken the largest value of each of every four pixels and set the output image to be such a value, as seen using the max() function--max pooling. The result did decrease in size, but I changed my output to be the same size, fit to 8 by 8, as explained.

C. The lecture for today (Coding with Convolutional Neural Network) compared the application of our previously specified deep neural network with a newly specified convolutional neural network. Instead of using the fashion_MNIST dataset, use the mnist dataset (the hand written letters) to train and compare your DNN and CNN output. Were you able to improve your model by adding the Conv2D and MaxPooling2D layers to your neural network? Plot the convolutions graphically, include them in your response and describe them. Edit the convolutions be changing the 32s to either 16 or 64 and describe what impact this had on accuracy and training time. What happens if you add more convolution layers?

c answer

