
C. Word Embeddings

1\. Why is using one-hot encoding an inefficient towards vectorizing a corpus of words? How are word embeddings different? (see this video https:// www.youtube.com/watch?v=EEk6OiOOT2c )

In a one-hot encoding, all (most) of the values are 0's, except one 1, which indicates the represented value. Only one of these bits can be "hot" or true. As a result, corpuses of words will have one out of tens/hundreds/thousands/millions of 0's, with only one 1, taking up a lot of space and not being as efficient. On the other hand, the word embeddings are dense types. They use a different type of encoding, which is not necessarily binary, with 0's and 1's, and are much more computationally efficient. With word embeddings, they can have more data stored in them, as well, to tell the relation with other words, and especially within sentences or as groupings (hence, having different values than just a binary 0-or-1 system). The parameters are also trainable by the model/program itself. Something interesting to note is that if words have similar encodings, then they may have similar meanings!

As a result, since one-hot encodings are better for vectorizing categorical features, it doesn't work as well for millions of different types of unique words where they can be stored in a more compact method, with large amounts.

2\. Compile and train the model from the tensorflow exercise. Plot the training and validation loss as well as accuracy. Post your plots and describe them.

![image000](https://github.com/dshuangg/responses/raw/master/image000.png)

3\. Stretch Goal: Follow the link to the Embedding Projector provided at the end of the exercise. Produce the visualization of your embeddings. Interpret your visualization. What is it describing? Is there relevance with regard to words that are proximate to each other?



D. Text Classification with an RNN

1\. Again compile and train the model from the tensorflow exercise. Plot the training and validation loss as well as accuracy. Stack two or more LSTM layers in your model. Post your plots and describe them.



